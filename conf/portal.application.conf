# Copyright 2014 Brandon Arp
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ~~~~~

# Secret key
# ~~~~~
# The secret key is used to secure cryptographics functions.
# If you deploy your application to several instances be sure to use the same key!
play.http.secret.key = "j;CsRfxs6n[6fA>Bb2^4@YVNdNw0omx=2L;=jqvGqfCuouukvF/KSrLJI?e:6xi4"

# The application languages
# ~~~~~
play.i18n.langs = ["en"]

# Global object class
# ~~~~~
# Define the Global object class for this application.
# Default to Global in the root package.
pidfile.path = "/dev/null"
play.server.pidfile.path="/dev/null"
play.modules.disabled += "play.core.ObjectMapperModule"
play.modules.enabled += "global.MainModule"
play.http.actionCreator = "global.ActionCreator"
play.http.errorHandler = "global.ErrorHandler"
play.http.filters = "global.Filters"
play.http.session.httpOnly = false
play.filters.cors.pathPrefixes = ["/v1/", "/api/v1/"]
play.filters.headers.contentSecurityPolicy = "script-src 'self' 'unsafe-eval'"

# Http Server
# ~~~~~
play.server.http.port = 8080

# Router
# ~~~~~
play.http.router = portal.Routes

# Health Provider
# ~~~~~
http.healthProvider.type = "com.arpnetworking.metrics.portal.health.DefaultHealthProvider"

# Features
# ~~~~~
portal.features {
  # Telemetry
  telemetry.enabled = true

  # Proxy
  proxy.enabled = true
  proxy.preferred = false

  # Host Registry
  hostRegistry.enabled = false

  # Alerts
  alerts.enabled = false

  # Rollups
  rollups.enabled = false

  # Reports
  reports.enabled = true

  # Metrics aggregator ports
  metricsAggregatorDaemonPorts = [7090]
}

# Metrics
# ~~~~~
metrics {
  cluster = "metrics_portal"
  service = "metrics_portal"
  uri = "http://localhost:7090"
  jvm.interval = "500 millis"
}

# Database
# ~~~~~
postgres.host = "localhost"
postgres.host = ${?PG_HOST}
postgres.port = 5432
postgres.port = ${?PG_PORT}
postgres.db = "metrics"
postgres.db = ${?PG_DB}

db {
  metrics_portal {
    username = "metrics_app"
    username = ${?PG_METRICS_APP_USER}
    password = "metrics_app_password"
    password = ${?PG_METRICS_APP_PASSWORD}
    url = "jdbc:postgresql://"${postgres.host}":"${postgres.port}"/"${postgres.db}"?currentSchema=portal"
    url = ${?PG_METRICS_URL}
    driver = "org.postgresql.Driver"

    hikaricp.poolName = "metrics_portal_dml"
    hikaricp.maximumPoolSize = 5
  }

  metrics_portal_ddl {
    username = "metrics_dba"
    username = ${?PG_METRICS_DBA_USER}
    password = "metrics_dba_password"
    password = ${?PG_METRICS_DBA_PASSWORD}
    url = "jdbc:postgresql://"${postgres.host}":"${postgres.port}"/"${postgres.db}"?currentSchema=portal"
    url = ${?PG_METRICS_URL}
    driver = "org.postgresql.Driver"

    migration.locations = ["common", "postgresql"]
    initOnMigrate = false
    validateOnMigrate = true
    encoding = "UTF-8"
    migration.auto = true
    migration.schemas = ["portal"]

    hikaricp.poolName = "metrics_portal_ddl"
    hikaricp.maximumPoolSize = 2
  }

  akka_ddl {
    username = "akka_dba"
    username = ${?PG_AKKA_DBA_USER}
    password = "akka_dba_password"
    password = ${?PG_AKKA_DBA_PASSWORD}
    url = "jdbc:postgresql://"${postgres.host}":"${postgres.port}"/"${postgres.db}"?currentSchema=akka"
    url = ${?PG_AKKA_URL}
    driver = "org.postgresql.Driver"

    migration.locations = ["common", "postgresql"]
    initOnMigrate = false
    validateOnMigrate = true
    encoding = "UTF-8"
    migration.auto = true
    migration.schemas = ["akka"]

    hikaricp.poolName = "akka_ddl"
    hikaricp.maximumPoolSize = 2
  }

  # NOTE: Please refer to main/postgres/initdb.d for how to initialize your Postgresql instance.
  # NOTE: The akka DML connection pool is configured below under Akka using Slick.
}

# Evolutions & Ebean
play.evolutions.enabled = false
play.modules.enabled += "org.flywaydb.play.PlayModule"
ebeanconfig.datasource.default = "metrics_portal"
play.ebean.defaultDatasource = "metrics_portal"
ebean.metrics_portal = ["models.ebean.*"]

# Cassandra alert repository
play.modules.enabled += "global.PillarModule"
#cassandra.db.default {
#  clusterName = "Metrics"
#  hosts = ["localhost"]
#  keyspace = "portal"
### See http://docs.datastax.com/en/cassandra/2.1/cassandra/architecture/architectureDataDistributeReplication_c.html
### for replication settings
#  replication {
#    class = "SimpleStrategy"
#    replication_factor = 1
#  }
#}

# Host repository
# ~~~~~
hostRepository {
  type = com.arpnetworking.metrics.portal.hosts.impl.DatabaseHostRepository
  hostQueryGenerator.type = "com.arpnetworking.metrics.portal.hosts.impl.DatabaseHostRepository$PostgresqlHostQueryGenerator"
}

# Host provider
# ~~~~~
hostProvider {
  type = com.arpnetworking.metrics.portal.hosts.impl.NoHostProvider
  initialDelay = "60s"
  interval = "1h"
}

# Alerts
# ~~~~~
alertRepository {
  type = com.arpnetworking.metrics.portal.alerts.impl.NoAlertRepository
  alertQueryGenerator.type = "com.arpnetworking.metrics.portal.alerts.impl.DatabaseAlertRepository$GenericQueryGenerator"
}

# Reports
# ~~~~~
reportRepository {
  type = com.arpnetworking.metrics.portal.reports.impl.NoReportRepository
  alertQueryGenerator.type = "com.arpnetworking.metrics.portal.reports.impl.DatabaseReportRepository$GenericQueryGenerator"
}

# Rollups
# ~~~~~
rollup {
  worker.count = 5
  fetch.interval = "1h"
  fetch.backoff = "5min"
  maxBackFill.periods = 2160
  metric.whitelist = []
  metric.blacklist = []
}

# KairosDB proxying
kairosdb.uri = "http://localhost:8000"

# Akka
# ~~~~~
akka {
  # Loggers to register at boot time (akka.event.Logging$DefaultLogger logs
  # to STDOUT)
  loggers = ["akka.event.slf4j.Slf4jLogger"]

  # Log level used by the configured loggers (see "loggers") as soon
  # as they have been started; before that, see "stdout-loglevel"
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  loglevel = "DEBUG"

  # Log level for the very basic logger activated during ActorSystem startup.
  # This logger prints the log messages to stdout (System.out).
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  stdout-loglevel = "DEBUG"

  # Filter of log events that is used by the LoggingAdapter before
  # publishing log events to the eventStream.
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  actor {
    provider="akka.cluster.ClusterActorRefProvider"
    debug.unhandled = on
  }
  cluster {
    seed-nodes=["akka.tcp://mportal@127.0.0.1:2558"]
    auto-down-unreachable-after = 300s
    roles = ["host_indexer", "rollup_metrics_discovery"]
    sharding {
      guardian-name="sharding"
      role=""
      retry-interval="2 s"
      buffer-size=100000
      handoff-timeout="60 s"
      rebalance-interval="10 s"
      snapshot-interval="720 s"
      state-store-mode="persistence"
      least-shard-allocation-strategy {
        rebalance-threshold=10
        max-simultaneous-rebalance=3
      }
    }
  }
  remote {
    log-remote-lifecycle-events="on"
    netty.tcp.hostname="127.0.0.1"
    netty.tcp.port=2558
  }
  persistence {
    journal {
      plugin="jdbc-journal"
      auto-start-journals = ["jdbc-journal"]
    }
    snapshot-store {
      plugin="jdbc-snapshot-store"
      auto-start-snapshot-stores = ["jdbc-snapshot-store"]
    }
  }
  http {
    client {
      parsing.max-content-length = 104857600
      idle-timeout = 600s
    }
    host-connection-pool {
      max-connections = 64
      max-open-requests = 512
    }
  }
}

jdbc-journal {
  slick = ${slick}
  tables.journal.schemaName = akka
}

jdbc-snapshot-store {
  slick = ${slick}
  tables.snapshot.schemaName = akka
}

jdbc-read-journal {
  slick = ${slick}
  tables.journal.schemaName = akka
}

slick {
  profile = "slick.jdbc.PostgresProfile$"
  db {
    host = "localhost"
    url = "jdbc:postgresql://localhost:5432/metrics?reWriteBatchedInserts=true"
    user = "akka_app"
    password = "akka_app_password"
    driver = "org.postgresql.Driver"
    numThreads = 5
    maxConnections = 5
    minConnections = 1
  }
}

play.akka.actor-system = "mportal"
play.akka.run-cs-from-phase = "before-cluster-shutdown"

play.server.akka.requestTimeout = 600s
play.server.http.idleTimeout = 600s
