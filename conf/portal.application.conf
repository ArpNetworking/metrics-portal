# Copyright 2014 Brandon Arp
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ~~~~~

include "cluster.conf"

# Secret key
# ~~~~~
# The secret key is used to secure cryptographics functions.
# If you deploy your application to several instances be sure to use the same key!
play.crypto.secret = "j;CsRfxs6n[6fA>Bb2^4@YVNdNw0omx=2L;=jqvGqfCuouukvF/KSrLJI?e:6xi4"

# The application languages
# ~~~~~
play.i18n.langs = ["en"]

# Global object class
# ~~~~~
# Define the Global object class for this application.
# Default to Global in the root package.
application.global = global.Global
play.modules.enabled += "global.MainModule"
play.http.requestHandler = "global.RequestHandler"
play.http.errorHandler = "global.ErrorHandler"

# Router
# ~~~~~
application.router = portal.Routes

# Metrics
# ~~~~~
metrics.cluster="metrics_portal"
metrics.service="metrics_portal"
metrics.name = "metrics-portal-query"
metrics.path = "logs"
metrics.jvm.interval = "500 millis"

# Database
# ~~~~~

# Switch between H2 and local Postgres

# Option 1: H2
db.default.url = "jdbc:h2:./target/h2/metrics:portal;AUTO_SERVER=TRUE;AUTO_SERVER_PORT=9091;MODE=PostgreSQL;INIT=create schema if not exists portal;DB_CLOSE_DELAY=-1"
db.default.driver = "org.h2.Driver"
db.metrics_portal_ddl.url = "jdbc:h2:./target/h2/metrics:portal;AUTO_SERVER=TRUE;AUTO_SERVER_PORT=9091;MODE=PostgreSQL;INIT=create schema if not exists portal;DB_CLOSE_DELAY=-1"
db.metrics_portal_ddl.driver = "org.h2.Driver"
db.metrics_portal_ddl.migration.locations = ["common", "h2"]

# Option 2: Postgresql
# NOTE: Assumes postgres with:
# - Database: "postgres" (created by default on mac)
# - Schema: "portal" (needs to be created)
# - Super User Login: "sa" (needs to be created)
# - Super User Password: "secret" (needs to be set)
#db.default.url = "jdbc:postgresql://localhost:5432/postgres?currentSchema=portal"
#db.default.driver = "org.postgresql.Driver"
#db.metrics_portal_ddl.url = "jdbc:postgresql://localhost:5432/postgres?currentSchema=portal"
#db.metrics_portal_ddl.driver = "org.postgresql.Driver"
#db.metrics_portal_ddl.migration.locations = ["common", "postgresql"]

# Common:
db.default.username = "sa"
db.default.password = "secret"
db.metrics_portal_ddl.username = "sa"
db.metrics_portal_ddl.password = "secret"
db.metrics_portal_ddl.initOnMigrate = false
db.metrics_portal_ddl.validateOnMigrate = true
db.metrics_portal_ddl.encoding = "UTF-8"
db.metrics_portal_ddl.migration.auto = true
db.metrics_portal_ddl.migration.schemas = ["portal"]

# Evolutions & Ebean
play.evolutions.enabled = false
play.modules.enabled += "org.flywaydb.play.PlayModule"
ebeanconfig.datasource.default = "default"
ebean.default = ["models.ebean.*"]

## EXAMPLE DATABASE CREATION ##
#
# First, connect to the admin database (e.g. postgres) with the root user (e.g. postgres):
#
#CREATE ROLE metrics_app LOGIN
#NOSUPERUSER INHERIT NOCREATEDB NOCREATEROLE NOREPLICATION CONNECTION LIMIT 10;
#CREATE ROLE metrics_dba LOGIN
#NOSUPERUSER INHERIT NOCREATEDB NOCREATEROLE NOREPLICATION CONNECTION LIMIT 6;
#CREATE DATABASE metrics WITH OWNER = metrics_dba
#ENCODING = 'UTF8'
#
# Next, connect to the metrics database with metrics_dba user:
#
#CREATE SCHEMA portal AUTHORIZATION metrics_dba;
#GRANT ALL ON SCHEMA portal TO metrics_dba;
#GRANT USAGE ON SCHEMA portal TO metrics_app;
#ALTER DEFAULT PRIVILEGES IN SCHEMA portal GRANT ALL ON TABLES TO metrics_dba;
#ALTER DEFAULT PRIVILEGES IN SCHEMA portal GRANT ALL ON SEQUENCES TO metrics_dba;
#ALTER DEFAULT PRIVILEGES IN SCHEMA portal GRANT ALL ON FUNCTIONS TO metrics_dba;
#ALTER DEFAULT PRIVILEGES IN SCHEMA portal GRANT ALL ON TABLES TO metrics_app;
#ALTER DEFAULT PRIVILEGES IN SCHEMA portal GRANT ALL ON SEQUENCES TO metrics_app;
#ALTER DEFAULT PRIVILEGES IN SCHEMA portal GRANT ALL ON FUNCTIONS TO metrics_app;

## SAMPLE DATABASE CONFIGURATION ##
#
#db.metrics_portal_dml.url = "jdbc:postgresql://localhost:5432/postgres"
#db.metrics_portal_dml.driver = "org.postgresql.Driver"
#db.metrics_portal_dml.username = "metrics_app"
#db.metrics_portal_dml.password = "metrics_app_password"
#db.metrics_portal_dml.hikaricp.poolName = "metrics_portal_dml"
#db.metrics_portal_dml.hikaricp.maximumPoolSize = 5
#db.metrics_portal_ddl.url = "jdbc:postgresql://localhost.snc1:5432/postgres"
#db.metrics_portal_ddl.driver = "org.postgresql.Driver"
#db.metrics_portal_ddl.username = "metrics_dba"
#db.metrics_portal_ddl.password = "metrics_dba_password"
#db.metrics_portal_ddl.initOnMigrate = false
#db.metrics_portal_ddl.validateOnMigrate = true
#db.metrics_portal_ddl.encoding = "UTF-8"
#db.metrics_portal_ddl.migration.auto = true
#db.metrics_portal_ddl.migration.schemas = ["portal"]
#db.metrics_portal_ddl.hikaricp.poolName = "metrics_portal_ddl"
#db.metrics_portal_ddl.hikaricp.maximumPoolSize = 2

# Elastic search
# ~~~~~
elasticSearch {
  cluster.name = "Testing"
  node.local = true
  node.data = true
  path.logs = logs
  path.data = data

  discovery.zen.ping.unicast.hosts = ""
  discovery.zen.minimum_master_nodes = 2

  # Hosts index
  # ~~~~~
  index.hosts {
    shards = 1
    replicas = 0
    refresh = "1s"
  }
}

# Host repository
# ~~~~~
hostRepository.type = com.arpnetworking.metrics.portal.hosts.impl.DatabaseHostRepository
hostRepository.hostQueryGenerator.type = "com.arpnetworking.metrics.portal.hosts.impl.DatabaseHostRepository$GenericQueryGenerator"

# Host provider
# ~~~~~
hostProvider {
  type = com.arpnetworking.metrics.portal.hosts.impl.RandomHostProvider
  initialDelay = 5 seconds
  interval = 5 seconds
}

# Alerts
# ~~~~~
alertRepository {
  type = com.arpnetworking.metrics.portal.alerts.impl.NoAlertRepository
  alertQueryGenerator.type = "com.arpnetworking.metrics.portal.alerts.impl.DatabaseAlertRepository$GenericQueryGenerator"
}

# Expressions
# ~~~~~
expressionRepository {
  type = com.arpnetworking.metrics.portal.expressions.impl.NoExpressionRepository
  expressionQueryGenerator.type = "com.arpnetworking.metrics.portal.expressions.impl.DatabaseExpressionRepository$GenericQueryGenerator"
}

# Akka
# ~~~~~
akka {
  # Loggers to register at boot time (akka.event.Logging$DefaultLogger logs
  # to STDOUT)
  loggers = ["akka.event.slf4j.Slf4jLogger"]

  # Log level used by the configured loggers (see "loggers") as soon
  # as they have been started; before that, see "stdout-loglevel"
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  loglevel = "DEBUG"

  # Log level for the very basic logger activated during ActorSystem startup.
  # This logger prints the log messages to stdout (System.out).
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  stdout-loglevel = "DEBUG"

  # Filter of log events that is used by the LoggingAdapter before
  # publishing log events to the eventStream.
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  actor {
    debug {
      unhandled = on
    }
  }
}
