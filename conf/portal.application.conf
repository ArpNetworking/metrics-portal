# Copyright 2014 Brandon Arp
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ~~~~~

# Secret key
# ~~~~~
# The secret key is used to secure cryptographics functions.
# If you deploy your application to several instances be sure to use the same key!
play.http.secret.key = "j;CsRfxs6n[6fA>Bb2^4@YVNdNw0omx=2L;=jqvGqfCuouukvF/KSrLJI?e:6xi4"

# The application languages
# ~~~~~
play.i18n.langs = ["en"]

# Global object class
# ~~~~~
# Define the Global object class for this application.
# Default to Global in the root package.
pidfile.path = "/dev/null"
play.server.pidfile.path="/dev/null"
play.modules.disabled += "play.core.ObjectMapperModule"
play.modules.enabled += "global.MainModule"
play.http.actionCreator = "global.ActionCreator"
play.http.errorHandler = "global.ErrorHandler"
play.http.filters = "global.Filters"
play.http.session.httpOnly = false
play.filters.cors.pathPrefixes = ["/v1/", "/api/v1/"]
play.filters.headers.contentSecurityPolicy = "script-src 'self' 'unsafe-eval'"

# Http Server
# ~~~~~
play.server.http.port = 8080

# Router
# ~~~~~
play.http.router = portal.Routes

# Health Provider
# ~~~~~
http.healthProvider.type = "com.arpnetworking.metrics.portal.health.DefaultHealthProvider"

# Features
# ~~~~~
portal.features {
  # Telemetry
  telemetry.enabled = true

  # Proxy
  proxy.enabled = true
  proxy.preferred = false

  # Host Registry
  hostRegistry.enabled = true

  # Expressions
  expressions.enabled = false

  # Alerts
  alerts.enabled = true

  # Rollups
  rollups.enabled = false

  # Reports
  reports.enabled = true

  # Metrics aggregator ports
  metricsAggregatorDaemonPorts = [7090]
}

# Metrics
# ~~~~~
metrics {
  cluster = "metrics_portal"
  service = "metrics_portal"
  uri = "http://localhost:7090"
  jvm.interval = "500 millis"
}

# Database
# ~~~~~
db {

  # Switch between H2 and local Postgres here and below in the Akka persistence configuration

  # Option 1: H2
  # ~~~~~
  default.username = "sa"
  default.password = "secret"
  default.url = "jdbc:h2:./target/h2/metrics_portal;IFEXISTS=FALSE;DATABASE_TO_UPPER=FALSE;AUTO_SERVER=TRUE;AUTO_SERVER_PORT=9091;MODE=PostgreSQL;INIT=create schema if not exists portal;DB_CLOSE_DELAY=-1"
  default.driver = "org.h2.Driver"

  metrics_portal_ddl.username = "sa"
  metrics_portal_ddl.password = "secret"
  metrics_portal_ddl.url = "jdbc:h2:./target/h2/metrics_portal;IFEXISTS=FALSE;DATABASE_TO_UPPER=FALSE;AUTO_SERVER=TRUE;AUTO_SERVER_PORT=9091;MODE=PostgreSQL;INIT=create schema if not exists portal;DB_CLOSE_DELAY=-1"
  metrics_portal_ddl.driver = "org.h2.Driver"
  metrics_portal_ddl.migration.locations = ["common", "h2"]

  akka.username = "sa"
  akka.password = "secret"
  akka.url = "jdbc:h2:./target/h2/metrics_portal;IFEXISTS=FALSE;DATABASE_TO_UPPER=FALSE;AUTO_SERVER=TRUE;AUTO_SERVER_PORT=9091;MODE=PostgreSQL;INIT=create schema if not exists akka;DB_CLOSE_DELAY=-1"
  akka.driver = "org.h2.Driver"
  akka.migration.locations = ["common", "h2"]

  # Option 2: Postgresql
  # ~~~~~
  #default.username = "metrics_app"
  #default.password = "metrics_app_password"
  #default.url = "jdbc:postgresql://localhost:5432/metrics?currentSchema=portal"
  #default.driver = "org.postgresql.Driver"
  #
  #metrics_portal_ddl.username = "metrics_dba"
  #metrics_portal_ddl.password = "metrics_dba_password"
  #metrics_portal_ddl.url = "jdbc:postgresql://localhost:5432/metrics?currentSchema=portal"
  #metrics_portal_ddl.driver = "org.postgresql.Driver"
  #metrics_portal_ddl.migration.locations = ["common", "postgresql"]
  #
  #akka.username = "akka_dba"
  #akka.password = "akka_dba_password"
  #akka.url = "jdbc:postgresql://localhost:5432/metrics?currentSchema=akka"
  #akka.driver = "org.postgresql.Driver"
  #akka.migration.locations = ["common", "postgresql"]

  # Common:
  # ~~~~~
  default.hikaricp.poolName = "metrics_portal_dml"
  default.hikaricp.maximumPoolSize = 5

  metrics_portal_ddl.initOnMigrate = false
  metrics_portal_ddl.validateOnMigrate = true
  metrics_portal_ddl.encoding = "UTF-8"
  metrics_portal_ddl.migration.auto = true
  metrics_portal_ddl.migration.schemas = ["portal"]
  metrics_portal_ddl.hikaricp.poolName = "metrics_portal_ddl"
  metrics_portal_ddl.hikaricp.maximumPoolSize = 2

  akka.initOnMigrate = false
  akka.validateOnMigrate = true
  akka.encoding = "UTF-8"
  akka.migration.auto = true
  akka.migration.schemas = ["akka"]
  akka.hikaricp.poolName = "akka_ddl"
  akka.hikaricp.maximumPoolSize = 2
}

# Evolutions & Ebean
play.evolutions.enabled = false
play.modules.enabled += "org.flywaydb.play.PlayModule"
ebeanconfig.datasource.default = "default"
play.ebean.defaultDatasource = "default"
ebean.default = ["models.ebean.*"]

## EXAMPLE DATABASE CREATION ##
#
# First, connect to the admin database (e.g. postgres) with the root user (e.g. postgres):
#
#CREATE ROLE metrics_app LOGIN;
#ALTER ROLE metrics_app WITH PASSWORD 'metrics_app_password';
#ALTER ROLE metrics_app WITH
#NOSUPERUSER INHERIT NOCREATEDB NOCREATEROLE NOREPLICATION CONNECTION LIMIT 100;
#CREATE ROLE metrics_dba LOGIN;
#ALTER ROLE metrics_dba WITH PASSWORD 'metrics_dba_password';
#ALTER ROLE metrics_dba WITH
#NOSUPERUSER INHERIT NOCREATEDB NOCREATEROLE NOREPLICATION CONNECTION LIMIT 6;
#
#CREATE ROLE akka_app LOGIN;
#ALTER ROLE akka_app WITH PASSWORD 'akka_app_password';
#ALTER ROLE akka_app WITH
#NOSUPERUSER INHERIT NOCREATEDB NOCREATEROLE NOREPLICATION CONNECTION LIMIT 100;
#CREATE ROLE akka_dba LOGIN;
#ALTER ROLE akka_dba WITH PASSWORD 'akka_dba_password';
#ALTER ROLE akka_dba WITH
#NOSUPERUSER INHERIT NOCREATEDB NOCREATEROLE NOREPLICATION CONNECTION LIMIT 6;
#
# Next, run this as a separate statement (typically cannot run in a transaction block):
#
#CREATE DATABASE metrics WITH OWNER = metrics_dba ENCODING = 'UTF8';
#
# Following which you can issue these together:
#
#GRANT CONNECT ON DATABASE metrics TO metrics_dba;
#GRANT CONNECT ON DATABASE metrics TO metrics_app;
#GRANT CONNECT ON DATABASE metrics TO akka_dba;
#GRANT CONNECT ON DATABASE metrics TO akka_app;
#
# Next, connect to the metrics database with the root user (e.g. postgres):
#
#CREATE EXTENSION IF NOT EXISTS btree_gin;
#
# Next, reconnect to the metrics database with metrics_dba user:
#
#CREATE SCHEMA portal AUTHORIZATION metrics_dba;
#GRANT ALL ON SCHEMA portal TO metrics_dba;
#GRANT USAGE ON SCHEMA portal TO metrics_app;
#CREATE SCHEMA akka;
#GRANT ALL ON SCHEMA akka TO akka_dba;
#GRANT USAGE ON SCHEMA akka TO akka_app;
#ALTER DEFAULT PRIVILEGES IN SCHEMA portal GRANT ALL ON TABLES TO metrics_dba;
#ALTER DEFAULT PRIVILEGES IN SCHEMA portal GRANT ALL ON SEQUENCES TO metrics_dba;
#ALTER DEFAULT PRIVILEGES IN SCHEMA portal GRANT ALL ON FUNCTIONS TO metrics_dba;
#ALTER DEFAULT PRIVILEGES IN SCHEMA portal GRANT ALL ON TYPES TO metrics_dba;
#ALTER DEFAULT PRIVILEGES IN SCHEMA portal GRANT ALL ON TABLES TO metrics_app;
#ALTER DEFAULT PRIVILEGES IN SCHEMA portal GRANT ALL ON SEQUENCES TO metrics_app;
#ALTER DEFAULT PRIVILEGES IN SCHEMA portal GRANT ALL ON FUNCTIONS TO metrics_app;
#ALTER DEFAULT PRIVILEGES IN SCHEMA portal GRANT ALL ON TYPES TO metrics_app;
#
# Next, reconnect to the metrics database with akka_dba user:
#
#ALTER DEFAULT PRIVILEGES IN SCHEMA akka GRANT ALL ON TABLES TO akka_dba;
#ALTER DEFAULT PRIVILEGES IN SCHEMA akka GRANT ALL ON SEQUENCES TO akka_dba;
#ALTER DEFAULT PRIVILEGES IN SCHEMA akka GRANT ALL ON FUNCTIONS TO akka_dba;
#ALTER DEFAULT PRIVILEGES IN SCHEMA akka GRANT ALL ON TYPES TO akka_dba;
#ALTER DEFAULT PRIVILEGES IN SCHEMA akka GRANT ALL ON TABLES TO akka_app;
#ALTER DEFAULT PRIVILEGES IN SCHEMA akka GRANT ALL ON SEQUENCES TO akka_app;
#ALTER DEFAULT PRIVILEGES IN SCHEMA akka GRANT ALL ON FUNCTIONS TO akka_app;
#ALTER DEFAULT PRIVILEGES IN SCHEMA akka GRANT ALL ON TYPES TO akka_app;

# Cassandra alert repository

play.modules.enabled += "global.PillarModule"
#cassandra.db.default {
#  clusterName = "Metrics"
#  hosts = ["localhost"]
#  keyspace = "portal"
## See http://docs.datastax.com/en/cassandra/2.1/cassandra/architecture/architectureDataDistributeReplication_c.html
## for replication settings
#  replication {
#    class = "SimpleStrategy"
#    replication_factor = 1
#  }
#}

# Elastic search
# ~~~~~
elasticSearch {
  cluster.name = "Testing"
  node.local = true
  node.data = true
  path.logs = logs
  path.data = data

  discovery.zen.ping.unicast.hosts = ""
  discovery.zen.minimum_master_nodes = 1

  # Hosts index
  # ~~~~~
  index.hosts {
    shards = 1
    replicas = 0
    refresh = "1s"
  }
}

# Host repository
# ~~~~~
hostRepository.type = com.arpnetworking.metrics.portal.hosts.impl.DatabaseHostRepository
hostRepository.hostQueryGenerator.type = "com.arpnetworking.metrics.portal.hosts.impl.DatabaseHostRepository$GenericQueryGenerator"

# Host provider
# ~~~~~
hostProvider {
  type = com.arpnetworking.metrics.portal.hosts.impl.RandomHostProvider
  targetOrganizationId = "0eb03110-2a36-4cb1-861f-7375afc98b9b"
  initialDelay = 5 seconds
  interval = 5 seconds
}

# Alerts
# ~~~~~
alertRepository {
  type = com.arpnetworking.metrics.portal.alerts.impl.NoAlertRepository
  alertQueryGenerator.type = "com.arpnetworking.metrics.portal.alerts.impl.DatabaseAlertRepository$GenericQueryGenerator"
}

# Reports
# ~~~~~
reportRepository {
  type = com.arpnetworking.metrics.portal.reports.impl.NoReportRepository
  alertQueryGenerator.type = "com.arpnetworking.metrics.portal.reports.impl.DatabaseReportRepository$GenericQueryGenerator"
}

# Expressions
# ~~~~~
expressionRepository {
  type = com.arpnetworking.metrics.portal.expressions.impl.NoExpressionRepository
  expressionQueryGenerator.type = "com.arpnetworking.metrics.portal.expressions.impl.DatabaseExpressionRepository$GenericQueryGenerator"
}

# Rollups
# ~~~~~
rollups {
  worker.count = 5
  fetch.interval = "1h"
  metric.whitelist = []
  metric.blacklist = []
}

# KairosDB proxying
kairosdb.uri = "http://localhost:8000"

# Akka
# ~~~~~
akka {
  # Loggers to register at boot time (akka.event.Logging$DefaultLogger logs
  # to STDOUT)
  loggers = ["akka.event.slf4j.Slf4jLogger"]

  # Log level used by the configured loggers (see "loggers") as soon
  # as they have been started; before that, see "stdout-loglevel"
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  loglevel = "DEBUG"

  # Log level for the very basic logger activated during ActorSystem startup.
  # This logger prints the log messages to stdout (System.out).
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  stdout-loglevel = "DEBUG"

  # Filter of log events that is used by the LoggingAdapter before
  # publishing log events to the eventStream.
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  actor {
    provider="akka.cluster.ClusterActorRefProvider"
    debug.unhandled = on
  }
  cluster {
    seed-nodes=["akka.tcp://mportal@127.0.0.1:2558"]
    auto-down-unreachable-after = 300s
    roles = ["host_indexer", "rollup_metrics_discovery"]
    sharding {
      guardian-name="sharding"
      role=""
      retry-interval="2 s"
      buffer-size=100000
      handoff-timeout="60 s"
      rebalance-interval="10 s"
      snapshot-interval="720 s"
      state-store-mode="persistence"
      least-shard-allocation-strategy {
        rebalance-threshold=10
        max-simultaneous-rebalance=3
      }
    }
  }
  remote {
    log-remote-lifecycle-events="on"
    netty.tcp.hostname="127.0.0.1"
    netty.tcp.port=2558
  }
  persistence {
    journal {
      plugin="jdbc-journal"
      auto-start-journals = ["jdbc-journal"]
    }
    snapshot-store {
      plugin="jdbc-snapshot-store"
      auto-start-snapshot-stores = ["jdbc-snapshot-store"]
    }
  }
  http {
    client {
      parsing.max-content-length = 104857600
      idle-timeout = 600s
    }
    host-connection-pool {
      max-connections = 64
      max-open-requests = 512
    }
  }
}

jdbc-journal {
  slick = ${slick}
  tables.journal.schemaName = akka
}

jdbc-snapshot-store {
  slick = ${slick}
  tables.snapshot.schemaName = akka
}

jdbc-read-journal {
  slick = ${slick}
  tables.journal.schemaName = akka
}

slick {
  # Option 1: H2
  # ~~~~~
  profile = "slick.jdbc.H2Profile$"
  # Option 2: Postgresql
  # ~~~~~
  #profile = "slick.jdbc.PostgresProfile$"
  db {
    # Option 1: H2
    # ~~~~~
    url = "jdbc:h2:./target/h2/metrics_portal;IFEXISTS=FALSE;DATABASE_TO_UPPER=FALSE;AUTO_SERVER=TRUE;AUTO_SERVER_PORT=9091;MODE=PostgreSQL;INIT=create schema if not exists akka;DB_CLOSE_DELAY=-1"
    user = "sa"
    password = "secret"
    driver = "org.h2.Driver"

    # Option 2: Postgresql
    # ~~~~~
    #host = "localhost"
    #url = "jdbc:postgresql://localhost:5432/metrics?reWriteBatchedInserts=true"
    #user = "akka_app"
    #password = "akka_app_password"
    #driver = "org.postgresql.Driver"

    # Common:
    # ~~~~~
    numThreads = 5
    maxConnections = 5
    minConnections = 1
  }
}

play.akka.actor-system = "mportal"
play.akka.run-cs-from-phase = "before-cluster-shutdown"

play.server.akka.requestTimeout = 600s
play.server.http.idleTimeout = 600s
